{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "load_dotenv(dotenv_path=\"/home/longview/Dev/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools for the agent to use\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Call to surf the web.\"\"\"\n",
    "    if \"sf\" in query.lower() or \"san francisco\" in query.lower():\n",
    "        return [\"It's 60 degrees and foggy.\"]\n",
    "    return [\"It's 90 degrees and sunny.\"]\n",
    "\n",
    "tools = [search]\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0).bind_tools(tools)\n",
    "\n",
    "# Define the function that determines wheter to continue or not\n",
    "def should_continue(state:MessagesState) -> Literal[\"tools\", END]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entrypoint as 'agent'\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use 'agent'.\n",
    "    # This means these are the edges taken after the 'agent' node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "# We now add a normal edge from 'tools' to 'agent'.\n",
    "# This means that after 'tools' is called, 'agent' node is called next.\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Initialize memory to persist state between graph runs\n",
    "checkpointer = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable.\n",
    "# Note that we're (optionally) passing the memory when compiling the graph\n",
    "app = workflow.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the search results, I can tell you that the current weather in San Francisco is:\\n\\nTemperature: 60 degrees Fahrenheit\\nConditions: Foggy\\n\\nSan Francisco is known for its microclimates and frequent fog, especially during the summer months. The temperature of 60째F (about 15.5째C) is quite typical for the city, which tends to have mild temperatures year-round. The fog, often referred to as \"Karl the Fog\" by locals, is a characteristic feature of San Francisco\\'s weather, particularly in the mornings and evenings.\\n\\nIs there anything else you\\'d like to know about the weather in San Francisco or any other location?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the Runnable\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thank you for your patience. I've searched again for the current weather in New York City, and the results show that the weather conditions remain the same as in our previous search:\\n\\nTemperature: 90 degrees Fahrenheit (approximately 32.2 degrees Celsius)\\nConditions: Sunny\\n\\nThis confirms that New York City is indeed experiencing hot and sunny weather. To provide some additional context:\\n\\n1. A temperature of 90째F is considered quite hot for many people and is typical of summer weather in New York City.\\n2. The sunny conditions mean there's likely little cloud cover, which can make the heat feel more intense due to direct sunlight.\\n3. It's important for people in New York to stay hydrated and seek shade when possible in such weather conditions.\\n4. This kind of weather is a stark contrast to the cooler, foggy conditions we found earlier in San Francisco (60째F and foggy).\\n\\nIf you're in New York or planning to visit, it would be wise to dress for hot weather, use sun protection, and stay hydrated.\\n\\nIs there anything specific about the New York weather you'd like to know more about? Or perhaps you're interested in the weather somewhere else?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"what about ny\")]},\n",
    "     config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "final_state[\"messages\"][-1].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
